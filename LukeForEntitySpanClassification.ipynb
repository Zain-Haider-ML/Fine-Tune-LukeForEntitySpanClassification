{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJF+rlKnKT0RBRQuGzMaQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zain-Haider-ML/Fine-Tune-LukeForEntitySpanClassification/blob/main/LukeForEntitySpanClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install seqeval git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "hTurcT0EYpK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "import copy\n",
        "import torch\n",
        "import seqeval.metrics\n",
        "from transformers import AutoTokenizer, LukeForEntitySpanClassification, Trainer, TrainingArguments, LukeConfig\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "R-KY7cb2YpLA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.read_json('/content/train_data__news.jsonl', lines=True)\n",
        "ds.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "49e7240b-e0e9-45a3-b734-0eedfc8d3982",
        "id": "F11oE7d_YpLB"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  HanAra Software , a subsidiary of South Korean...   \n",
              "1  STMI will provide technical assistance and tra...   \n",
              "2  â€™s infrastructure business and working togethe...   \n",
              "3  In this partnership, AkinovA and Benchmark Lab...   \n",
              "4  About Sarnova and Bound Tree Medical Sarnova a...   \n",
              "\n",
              "                                               spans       date   annotator  \\\n",
              "0  [{'start': 0, 'end': 15, 'label': 'ORG'}, {'st... 2024-10-16        alex   \n",
              "1  [{'start': 0, 'end': 4, 'label': 'ORG'}, {'sta... 2024-10-29  alex-feher   \n",
              "2         [{'start': 51, 'end': 71, 'label': 'ORG'}] 2024-10-25        alex   \n",
              "3  [{'start': 21, 'end': 28, 'label': 'ORG'}, {'s... 2024-10-29  alex-feher   \n",
              "4  [{'start': 6, 'end': 13, 'label': 'ORG'}, {'st... 2024-10-18       feher   \n",
              "\n",
              "        batch   ind  \n",
              "0  ner-news-3  1168  \n",
              "1  ner-news-5  2470  \n",
              "2  ner-news-5  1969  \n",
              "3  ner-news-5  1862  \n",
              "4  ner-news-3  1075  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d61e0671-2b8f-452f-9506-03ac24ca9a38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spans</th>\n",
              "      <th>date</th>\n",
              "      <th>annotator</th>\n",
              "      <th>batch</th>\n",
              "      <th>ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HanAra Software , a subsidiary of South Korean...</td>\n",
              "      <td>[{'start': 0, 'end': 15, 'label': 'ORG'}, {'st...</td>\n",
              "      <td>2024-10-16</td>\n",
              "      <td>alex</td>\n",
              "      <td>ner-news-3</td>\n",
              "      <td>1168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>STMI will provide technical assistance and tra...</td>\n",
              "      <td>[{'start': 0, 'end': 4, 'label': 'ORG'}, {'sta...</td>\n",
              "      <td>2024-10-29</td>\n",
              "      <td>alex-feher</td>\n",
              "      <td>ner-news-5</td>\n",
              "      <td>2470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>â€™s infrastructure business and working togethe...</td>\n",
              "      <td>[{'start': 51, 'end': 71, 'label': 'ORG'}]</td>\n",
              "      <td>2024-10-25</td>\n",
              "      <td>alex</td>\n",
              "      <td>ner-news-5</td>\n",
              "      <td>1969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this partnership, AkinovA and Benchmark Lab...</td>\n",
              "      <td>[{'start': 21, 'end': 28, 'label': 'ORG'}, {'s...</td>\n",
              "      <td>2024-10-29</td>\n",
              "      <td>alex-feher</td>\n",
              "      <td>ner-news-5</td>\n",
              "      <td>1862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>About Sarnova and Bound Tree Medical Sarnova a...</td>\n",
              "      <td>[{'start': 6, 'end': 13, 'label': 'ORG'}, {'st...</td>\n",
              "      <td>2024-10-18</td>\n",
              "      <td>feher</td>\n",
              "      <td>ner-news-3</td>\n",
              "      <td>1075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d61e0671-2b8f-452f-9506-03ac24ca9a38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d61e0671-2b8f-452f-9506-03ac24ca9a38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d61e0671-2b8f-452f-9506-03ac24ca9a38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d37df50f-0930-4bd4-9f28-3d0d812ed3f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d37df50f-0930-4bd4-9f28-3d0d812ed3f5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d37df50f-0930-4bd4-9f28-3d0d812ed3f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ds",
              "summary": "{\n  \"name\": \"ds\",\n  \"rows\": 1724,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1724,\n        \"samples\": [\n          \"LONDON, Oct. 29, 2020 (GLOBE NEWSWIRE) -- Click on, or paste the following link into your web browser, to view the full associated PDF document.\",\n          \"Our trading subsidiaries in Preston, Durham and Wimbledon will now operate under a single national entity, BAKO Limited, while operational systems will also be consolidated to help streamline and boost efficiency of operations across the entire UK.\",\n          \"Yum! Brands (owner of KFC, Taco Bell, and Pizza Hut) is giving time off to workers at company-owned locations and corporate employees \\u2014 though considering the company is 98 percent franchised and whittled down its direct employees from 90,000 to 34,000 people between 2016 and 2019, that may not affect too many of the 1.5 million global \\u201cfranchise associates.\\u201d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spans\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-01-10 00:00:00\",\n        \"max\": \"2024-11-10 00:00:00\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"2024-01-10 00:00:00\",\n          \"2024-10-21 00:00:00\",\n          \"2024-10-16 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotator\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"alex\",\n          \"alex-feher\",\n          \"baris-emily\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"ner-news-3\",\n          \"ner-news-5\",\n          \"ner-news-0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ind\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 739,\n        \"min\": 0,\n        \"max\": 2567,\n        \"num_unique_values\": 1724,\n        \"samples\": [\n          1877,\n          1191,\n          941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the label-to-index mapping\n",
        "\n",
        "label_to_index = {\n",
        "    'NIL':0,\n",
        "    \"LOC\": 1,\n",
        "    \"JOB\": 2,\n",
        "    \"MONEY\": 3,\n",
        "    \"ORG\": 4,\n",
        "    \"PERSON\": 5,\n",
        "    'DATE':6,\n",
        "}\n",
        "\n",
        "index_to_label = {\n",
        "    0: \"NIL\",\n",
        "    1: \"LOC\",\n",
        "    2: \"JOB\",\n",
        "    3: \"MONEY\",\n",
        "    4: \"ORG\",\n",
        "    5: \"PERSON\",\n",
        "    6: \"DATE\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_entity_spans_and_labels(ds, label_to_index, num_samples=25):\n",
        "    \"\"\"\n",
        "    Extracts start and end positions of entities and their corresponding labels from the dataset.\n",
        "\n",
        "    Args:\n",
        "        ds (dict): A dataset containing spans, where each span is a list of entities with 'start', 'end', and 'label' keys.\n",
        "        label_to_index (dict): A dictionary mapping label names to their respective indices.\n",
        "        num_samples (int): The number of spans to process from the dataset.\n",
        "\n",
        "    Returns:\n",
        "        entity_spans_all (list): A list containing lists of (start, end) pairs for each span.\n",
        "        all_labels (list): A list containing lists of label indices for each span.\n",
        "    \"\"\"\n",
        "    entity_spans_all = []  # List to store spans for each span in the dataset\n",
        "    all_labels = []  # List to hold the labels for each span\n",
        "\n",
        "    # Iterate over the specified number of spans in the dataset\n",
        "    for span in ds['spans'][:num_samples]:\n",
        "        entity_spans = []  # Temporary list to hold (start, end) pairs for the current span\n",
        "        labels = []  # Temporary list to hold labels for the current span\n",
        "\n",
        "        # Extract the start, end positions and labels from the current span\n",
        "        for i in span:\n",
        "            # Extract start and end positions\n",
        "            start_pos, end_pos = i['start'], i['end']\n",
        "            entity_spans.append((start_pos, end_pos))\n",
        "\n",
        "            # Extract and map the label to its index\n",
        "            labels.append(label_to_index[i['label']])\n",
        "\n",
        "        # Append the list of (start, end) pairs for this span to entity_spans_all\n",
        "        entity_spans_all.append(entity_spans)\n",
        "\n",
        "        # Append the list of label indices for this span to all_labels\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    return entity_spans_all, all_labels\n"
      ],
      "metadata": {
        "id": "04g5Y612wwvQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 500\n",
        "val_num_samples = 110\n",
        "\n",
        "entity_spans_all, all_labels  = extract_entity_spans_and_labels(ds, label_to_index, num_samples + val_num_samples)\n",
        "print(entity_spans_all[:2], all_labels[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIJ9pkBzwyfU",
        "outputId": "ae2cb925-3156-4d21-97b2-b42e432b027a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 15), (53, 67), (82, 88)], [(0, 4), (73, 113), (122, 127), (139, 154), (158, 164)]] [[4, 4, 1], [4, 4, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(ds['text'][:num_samples + val_num_samples])\n",
        "\n",
        "len(texts), len(entity_spans_all), len(all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efjEWNfxw4RD",
        "outputId": "2f042fdb-2aea-4c91-8ef2-55c56f28f9da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 610, 610)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0], entity_spans_all[0], all_labels[0], len(texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCxGiijixDhG",
        "outputId": "3180ff23-aa1b-4313-9a2a-2d0746d82f9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('HanAra Software , a subsidiary of South Korean-based BNF Technology, has selected Austin as its North American headquarters and plans to triple in size.',\n",
              " [(0, 15), (53, 67), (82, 88)],\n",
              " [4, 4, 1],\n",
              " 152)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process each text\n",
        "all_token_labels = []  # Store token labels for each text\n",
        "all_token_spans = []   # Store token spans for each text\n",
        "\n",
        "for text, entity_spans, labels in zip(texts, entity_spans_all, all_labels):\n",
        "    doc = nlp(text)  # Tokenize the text\n",
        "    token_labels = [label_to_index['NIL']] * len(doc)  # Initialize NIL labels\n",
        "    token_spans = [(token.idx, token.idx + len(token)) for token in doc]  # Store spans\n",
        "\n",
        "    # Assign entity labels to corresponding tokens\n",
        "    for (start, end), label in zip(entity_spans, labels):\n",
        "        for token in doc:\n",
        "            if token.idx >= start and token.idx < end:\n",
        "                token_labels[token.i] = label  # Assign correct label\n",
        "\n",
        "    all_token_labels.append(token_labels)  # Save labels\n",
        "    all_token_spans.append(token_spans)    # Save spans"
      ],
      "metadata": {
        "id": "epklj1PGxHIX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_token_labels), len(all_token_spans), len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwPEAuBwxNPb",
        "outputId": "71bdc997-eab3-4fe5-99a0-912ebd490741"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 610, 610)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"text\": texts[:num_samples],\n",
        "    \"entity_spans\": all_token_spans[:num_samples],\n",
        "    \"labels\": all_token_labels[:num_samples],\n",
        "}\n",
        "\n",
        "len(data['text']), len(data['entity_spans']), len(data['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jb8iOqDxWto",
        "outputId": "aefc83cf-c318-434d-cab2-046740367858"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 500, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = {\n",
        "    \"text\": texts[num_samples:],\n",
        "    \"entity_spans\": all_token_spans[num_samples:],\n",
        "    \"labels\": all_token_labels[num_samples:],\n",
        "}\n",
        "\n",
        "len(val_data['text']), len(val_data['entity_spans']), len(val_data['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5zj0xlBxhMW",
        "outputId": "6f094233-4a97-4d41-e828-06175653060c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(110, 110, 110)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for l, i in zip(data['labels'], data['entity_spans']):\n",
        "  # print(len(l), len(i))\n",
        "  if len(l) != len(i):\n",
        "    print(len(l), len(i))\n",
        "\n",
        "for l, i in zip(val_data['labels'], val_data['entity_spans']):\n",
        "  # print(len(l), len(i))\n",
        "  if len(l) != len(i):\n",
        "    print(len(l), len(i))"
      ],
      "metadata": {
        "id": "w4L1QrFuxpGo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_labels(labels, max_len, pad_value=-100):\n",
        "    return [lbl + [pad_value] * (max_len - len(lbl)) for lbl in labels]"
      ],
      "metadata": {
        "id": "9rZtftEIx1lo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_entities = max(len(spans) for spans in data[\"entity_spans\"])\n",
        "val_max_entities = max(len(spans) for spans in val_data[\"entity_spans\"])\n",
        "\n",
        "print(max_entities, val_max_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5RRpe0Yx9wN",
        "outputId": "c4f1bb44-5b34-453f-bd51-1ab2fe0727e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "261 229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(label_to_index)\n",
        "print('num_labels = ', num_labels)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device = ', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-tFBcCiyGVG",
        "outputId": "cba6fd59-fdeb-48f7-8301-2a9787ec1be9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_labels =  7\n",
            "device =  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = LukeConfig.from_pretrained(\"studio-ousia/luke-large-finetuned-conll-2003\",\n",
        "                                    label2id=label_to_index, id2label=index_to_label,\n",
        "                                    num_labels=num_labels)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"studio-ousia/luke-large-finetuned-conll-2003\")\n",
        "model = LukeForEntitySpanClassification.from_pretrained(\"studio-ousia/luke-large-finetuned-conll-2003\",\n",
        "                                                        config=config, ignore_mismatched_sizes=True, ).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551,
          "referenced_widgets": [
            "17410e24120641ad8aee2e05bd33392b",
            "73a577027936426fbbf327b71cff78cd",
            "91ac1b44c0304e7aab89f73d18a9d089",
            "cc0de8dd17274adfa75806fc262db64a",
            "9e0d1385317c446daa009bee6538622e",
            "82d98eb97307404dbb486072ddd9611d",
            "c3059218654f45469b177bc10243c28f",
            "bc5956858d0b4bf29498bf338733e10e",
            "8e92ddd0f61042ed81a07186deab58eb",
            "4ac92576dbbd4433b9d3fea98cb3a5da",
            "2684dd7076604bb4ab3879296726c723",
            "9093a48c95564786af6908779ecf802e",
            "2f812ca1fc954cb88f023dee99ba5889",
            "4d88bcdf6b0c426294da942a559c17e8",
            "912fc046535a487882f9fb95167bf5f9",
            "61cc317dcd2d424cade1922c7921c4e1",
            "e82597c227d44f378348a3359ef99736",
            "9c1ca42e5b5e4e8195692419e0971714",
            "0ccbb6807fb14452bd9f171a7214883d",
            "3cc5aca121a841aeba7cb002e87c99de",
            "f82379fdf36f4945996c53526a43539d",
            "ed60047da6e742059ef0c1eae19c8d80",
            "7da4bf3081224fd19c9223039fea0fc8",
            "569dd67d4beb48cbbcaa4eb8d7710efc",
            "b2288478441443729f460dad59171cab",
            "6b9aefa2f808407eae5837a38e49b0ae",
            "2a23422ef4024f50bff17083754b2dc0",
            "57399d5e701148f7becf3bbf003b77f6",
            "ad5f1dd4876d4988846a41f2b3d57d1f",
            "f52c26bb9f8847a3b858fbdcbd7b0cba",
            "b74053c390b14a72bf7177aa61b973ed",
            "6f2ca450e9a247a78535b87a3e67d7e0",
            "fa61f0148e1f4b0a94d9b3269164ddf1",
            "135cdaef69be4c628d9dc05b45b9ee8f",
            "115331c39d0441f0b2bcb7b006845de4",
            "09fd472b86e64fe39e09d45ac65ff119",
            "269b7ecf40d34e8aac4d8dfd4cf9d203",
            "c0c4ac03dfb4440ea7b28495c63616ce",
            "517411a8627c4108a8cb5d995042d1bd",
            "3334c96441344b92bab06dcde590c58b",
            "939711c35d29455d97c6da03f5c3417a",
            "8d014bf8b3ac48ae83573268dffa8a96",
            "7f861e708f3845c4b0dd6ec60f0879b2",
            "fab863a2cd654aafac387f7ce1320f94",
            "f3ef56a8e99b49bb9ec2e2d2e6dfc1b5",
            "00259da995334925b1cd998ba47f66f8",
            "569475eda4ae4919beeabbbf1004c852",
            "55670fc51bc24b34bcd2f2733a6bdc4b",
            "124d3a5dcd0d4447992c9b74c228c2ee",
            "8320198099cb49338103660340629afd",
            "567110d62d174a79b6be53aec4ba676a",
            "e75a7d6daab84eaf926ab7567378267d",
            "b4ce7859f9d14f04970c26789d59deb0",
            "ccd043b86c76483d82ee0c0d5aecb277",
            "174f4671f98a4dbcb692ee03f16f9c4b",
            "e5abf68d9ebe46369f8bc1b2b870f0af",
            "47874019bba24f8ebe2049ab35719e8b",
            "cd36825dbf624a38bfb78960eb90cce9",
            "cf244432740240959ac26a1c7b632ea0",
            "c97c324c46e841ffb9aefb08150227e3",
            "915983160ab343239e74ec9bdf4db970",
            "8cdbbfaa736242f089f90764e6170b12",
            "38f4820c767d4f2e81660ac1b384f4aa",
            "2ccfa8282b1a4c1b8a2265d351f0021c",
            "a93930ceb00b43a7a25fdfa42f0d61ef",
            "86eb053934be46fbbcffadfbe8b16e79",
            "4b842b1111af44508886d6836301ce38",
            "368eaeff791b4c9aa2895dfa7ed03526",
            "9453729387e148c394d1e7afe31c700c",
            "c8c545fa7b8643aa816c0794718e79e6",
            "e2deef54f50843bdb3616893cb5801c1",
            "821912fbbaaa41d2b021b4a65c0fbda8",
            "5e37bdf9327b46448446dd031c0688c4",
            "852c677cd64d44beb6004972eb6f9b69",
            "c6998e24300946fcaca32cfba720eef8",
            "ff5c55bbf56548fdb8bc4be7d0ec27d7",
            "09e38187177044a9b0a5c04a52e80f6e",
            "5aad1ebd35e945959cb7d765004c61db",
            "5b6061288e9f48e89bc88b2e1c6434ef",
            "3ec47d8309864a338f5deeb892082f9a",
            "09cc5f1f9db34ec5881959259545bb9d",
            "1a72f70b470a4084a4146c18136695bf",
            "87acab9c85d84ccda6d17f3b12fdb4a2",
            "38a25a097ec543adb9af59dc18e67382",
            "39c00bfb36e545ec9de7ae9becab095b",
            "f10e3d060b504659bed42c7af29d8947",
            "dcd08ae68cc446b38c79ccb964826c2f",
            "f134198b81564c8db21b1e71080e5915",
            "9a64c67b3073426f9904921a813b3a3e",
            "ade8a01f009845b4881752eadc475553",
            "2cf981210790486ba31c48aea08b0108",
            "66f9f284fdc548d5bd59982a73f720bb",
            "ef9a405e44cd46339568f7bdfbf928a5",
            "cea77c520dc24977a09396e3a7df6018",
            "06904d83958c4abaaa15e2e3b36f3ed3",
            "f6108d3d9c774224aa107849aa8ccd30",
            "8e10a17cec0846d4ad54603783eb0094",
            "5f545441f14e42109865c9329eb28134",
            "7b7084c7af864233b41aaf89dd4acef4"
          ]
        },
        "id": "wXywryyUyC3W",
        "outputId": "f99eb50e-0b7b-43a7-f1bf-cfa122545f7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17410e24120641ad8aee2e05bd33392b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.70k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9093a48c95564786af6908779ecf802e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7da4bf3081224fd19c9223039fea0fc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "135cdaef69be4c628d9dc05b45b9ee8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "entity_vocab.json:   0%|          | 0.00/15.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3ef56a8e99b49bb9ec2e2d2e6dfc1b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/33.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5abf68d9ebe46369f8bc1b2b870f0af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b842b1111af44508886d6836301ce38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aad1ebd35e945959cb7d765004c61db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a64c67b3073426f9904921a813b3a3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at studio-ousia/luke-large-finetuned-conll-2003 were not used when initializing LukeForEntitySpanClassification: ['luke.embeddings.position_ids']\n",
            "- This IS expected if you are initializing LukeForEntitySpanClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LukeForEntitySpanClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LukeForEntitySpanClassification were not initialized from the model checkpoint at studio-ousia/luke-large-finetuned-conll-2003 and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([5, 3072]) in the checkpoint and torch.Size([7, 3072]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_inputs = tokenizer(\n",
        "    data['text'], entity_spans=data['entity_spans'], padding=True, truncation=True,\n",
        "    return_tensors=\"pt\", max_length=512, max_entity_length = 512).to(device)\n",
        "\n",
        "val_tokenized_inputs = tokenizer(\n",
        "    val_data['text'], entity_spans=val_data['entity_spans'], padding=True, truncation=True,\n",
        "    return_tensors=\"pt\", max_length=512, max_entity_length = 512).to(device)\n",
        "\n",
        "\n",
        "\n",
        "tokenized_inputs['labels'] = torch.tensor(pad_labels(data['labels'], max_entities), dtype=torch.long, device=device)\n",
        "tokenized_inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}\n",
        "\n",
        "val_tokenized_inputs['labels'] = torch.tensor(pad_labels(val_data['labels'], val_max_entities), dtype=torch.long, device=device)\n",
        "val_tokenized_inputs = {k: v.to(device) for k, v in val_tokenized_inputs.items()}\n"
      ],
      "metadata": {
        "id": "1ghvRwlnxxIv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_inputs['entity_ids'].shape, tokenized_inputs['entity_position_ids'].shape, tokenized_inputs['attention_mask'].shape, tokenized_inputs['entity_attention_mask'].shape, tokenized_inputs['labels'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_6yB0UpyzJ0",
        "outputId": "60f7d812-44dc-4142-bee2-fc69f5c97e75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([500, 261]),\n",
              " torch.Size([500, 261, 30]),\n",
              " torch.Size([500, 405]),\n",
              " torch.Size([500, 261]),\n",
              " torch.Size([500, 261]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_tokenized_inputs['entity_ids'].shape, val_tokenized_inputs['entity_position_ids'].shape, val_tokenized_inputs['attention_mask'].shape, val_tokenized_inputs['labels'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yrKYwvgy24_",
        "outputId": "215cdb72-84c1-4333-cc09-5bb5c37632ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([110, 229]),\n",
              " torch.Size([110, 229, 30]),\n",
              " torch.Size([110, 268]),\n",
              " torch.Size([110, 229]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_dict(tokenized_inputs)\n",
        "val_dataset = Dataset.from_dict(val_tokenized_inputs)"
      ],
      "metadata": {
        "id": "YFgqCTxzy727"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=6e-6,  # Reduce learning rate for stability\n",
        "    per_device_train_batch_size=2,  # Increase batch size\n",
        "    per_device_eval_batch_size=2,  # Increase batch size\n",
        "    gradient_accumulation_steps=2,  # Reduce accumulation to adjust for batch size increase\n",
        "    num_train_epochs=7,  # Increase epochs for better learning\n",
        "    weight_decay=0.06,  # Increase weight decay to prevent overfitting\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,  # Reduce logging frequency to avoid overhead\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=2,  # Prevent excessive checkpoints\n",
        "    load_best_model_at_end=True,  # Ensure best model is kept\n",
        ")\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "plnFcRptzACq",
        "outputId": "9cc9c6e5-a25a-4913-a949-9714e8419700"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [875/875 41:46, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.147600</td>\n",
              "      <td>0.086899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>0.066651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.058100</td>\n",
              "      <td>0.069455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.023700</td>\n",
              "      <td>0.076363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>0.078133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.024300</td>\n",
              "      <td>0.082096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.083028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=875, training_loss=0.08628214403986931, metrics={'train_runtime': 2509.237, 'train_samples_per_second': 1.395, 'train_steps_per_second': 0.349, 'total_flos': 3225248469135000.0, 'train_loss': 0.08628214403986931, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/fine-tuned_model/\")\n",
        "tokenizer.save_pretrained(\"/content/fine-tuned_model/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upFfaa_JzD3D",
        "outputId": "60339921-c8c8-4d39-8557-549495a2d7ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/fine-tuned_model/tokenizer_config.json',\n",
              " '/content/fine-tuned_model/special_tokens_map.json',\n",
              " '/content/fine-tuned_model/vocab.json',\n",
              " '/content/fine-tuned_model/merges.txt',\n",
              " '/content/fine-tuned_model/entity_vocab.json',\n",
              " '/content/fine-tuned_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device = ', device)\n",
        "# Load model and tokenizer\n",
        "model_path = \"/content/fine-tuned_model\"\n",
        "ft_model = LukeForEntitySpanClassification.from_pretrained(model_path, ignore_mismatched_sizes=True).to(device)\n",
        "\n",
        "ft_tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO182Nu360la",
        "outputId": "5ea2fc18-166e-4b69-c5e2-832ad135ee4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device =  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IteLjVSj68Eb",
        "outputId": "0bc8e6a6-b3b9-46e6-9616-9b1ab1f57985"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NIL', 1: 'LOC', 2: 'JOB', 3: 'MONEY', 4: 'ORG', 5: 'PERSON', 6: 'DATE'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recognizing named entities in a text:\n",
        "Finally, we extract named entities from a text using the fine-tuned model. The input text is tokenized using SpaCy.\n",
        "\n",
        "It extracts entity spans, tokenizes text, sends it to a GPU-based model, and constructs an IOB2 label sequence.\n"
      ],
      "metadata": {
        "id": "rYQN2lw4UEVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load text and model\n",
        "text = ds['text'][801]  # Get the second-last text sample\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Generate entity spans\n",
        "entity_spans = []\n",
        "original_word_spans = []\n",
        "for token_start in doc:\n",
        "    for token_end in doc[token_start.i:]:\n",
        "        entity_spans.append((token_start.idx, token_end.idx + len(token_end)))\n",
        "        original_word_spans.append((token_start.i, token_end.i + 1))\n",
        "\n",
        "# Tokenize and send to GPU\n",
        "inputs = ft_tokenizer(text, entity_spans=entity_spans, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    outputs = ft_model(**inputs)\n",
        "\n",
        "logits = outputs.logits\n",
        "max_logits, max_indices = logits[0].max(dim=1)\n",
        "\n",
        "# Process predictions\n",
        "predictions = []\n",
        "for logit, index, span in zip(max_logits, max_indices, original_word_spans):\n",
        "    if index != 0:  # The span is not NIL\n",
        "        predictions.append((logit, span, ft_model.config.id2label[int(index)]))\n",
        "\n",
        "# Construct an IOB2 label sequence\n",
        "predicted_sequence = [\"O\"] * len(doc)\n",
        "\n",
        "for _, span, label in sorted(predictions, key=lambda o: o[0], reverse=True):\n",
        "    # Check if any token within the span is already labeled\n",
        "    if all(token == \"O\" for token in predicted_sequence[span[0] : span[1]]):\n",
        "        predicted_sequence[span[0]] = \"B-\" + label  # First token gets \"B-\"\n",
        "\n",
        "        # If the span covers multiple tokens, assign \"I-\" to the rest\n",
        "        for i in range(span[0] + 1, span[1]):\n",
        "            predicted_sequence[i] = \"I-\" + label\n",
        "\n",
        "# Print results\n",
        "for token, label in zip(doc, predicted_sequence):\n",
        "    print(token, label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qForyUOX6_NC",
        "outputId": "5baf5329-b9b5-4bf9-e988-473dd97a170c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our O\n",
            "trading O\n",
            "subsidiaries O\n",
            "in O\n",
            "Preston B-LOC\n",
            ", O\n",
            "Durham B-LOC\n",
            "and O\n",
            "Wimbledon B-LOC\n",
            "will O\n",
            "now O\n",
            "operate O\n",
            "under O\n",
            "a O\n",
            "single O\n",
            "national O\n",
            "entity O\n",
            ", O\n",
            "BAKO B-ORG\n",
            "Limited B-ORG\n",
            ". O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Measuring performance"
      ],
      "metadata": {
        "id": "7v_0TRIYVB5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Due to limited GPU computational power, I am using only 20 examples for inference to measure performance.\""
      ],
      "metadata": {
        "id": "WE165e3dZNmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples_data = ds[1000:1020].reset_index(drop=True)\n",
        "\n",
        "test_texts = test_examples_data['text']\n",
        "_, all_labels_for_test  = extract_entity_spans_and_labels(test_examples_data, label_to_index, 100)\n",
        "\n",
        "print(all_labels_for_test[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghRGcAKcUj2Q",
        "outputId": "d1101490-02e9-4805-e2fa-211aae26b943"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 5], [4, 1, 6, 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples = {\n",
        "    \"text\": test_texts,\n",
        "    \"labels\": all_labels_for_test,\n",
        "}\n",
        "\n",
        "len(test_examples['text']),  len(test_examples['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxpy7iL9UjyB",
        "outputId": "818c5078-1d8e-46e9-82b2-9316c595595d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'test_examples' dictionary into a list of dictionaries\n",
        "test_examples_list = []\n",
        "for i in range(len(test_examples['text'])):\n",
        "    example = {}\n",
        "    for key in test_examples:  # Iterate through keys ('text', 'labels')\n",
        "        example[key] = test_examples[key][i]  # Copy values for the current index\n",
        "    test_examples_list.append(example)"
      ],
      "metadata": {
        "id": "9Q2u1_peUjtp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples_list[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGcZeQ7ZUjpb",
        "outputId": "54e44c46-f6bc-429a-f55f-07e45a3540f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Chen and Merk were initially apprehensive about hosting a virtual fair of this scale.',\n",
              "  'labels': [5, 5]},\n",
              " {'text': 'Airbus turns to Germany to put its pions in cybersecurity. The European aviation giant announced Monday 25. March the acquisition of Infodas, a German company specializing in cybersecurity, in order to â€œfortify its portfolioâ€ in this field.',\n",
              "  'labels': [4, 1, 6, 4]}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the SpaCy model for tokenization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize lists to store outputs for all text samples\n",
        "all_token_labels = []           # Stores token labels for each text\n",
        "all_token_spans = []            # Stores entity spans for each text\n",
        "all_logits = []                 # Stores model logits for predictions\n",
        "all_original_word_spans = []    # Stores original word spans for reference\n",
        "all_length = []                 # Stores text lengths\n",
        "\n",
        "# Iterate through the test examples\n",
        "for example in test_examples_list:\n",
        "    torch.cuda.empty_cache()\n",
        "    text, labels = example['text'], example['labels']\n",
        "\n",
        "    # Tokenize the text using SpaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Generate entity spans from tokenized text\n",
        "    entity_spans = []\n",
        "    original_word_spans = []\n",
        "    for token_start in doc:\n",
        "        for token_end in doc[token_start.i:]:\n",
        "            entity_spans.append((token_start.idx, token_end.idx + len(token_end)))\n",
        "            original_word_spans.append((token_start.i, token_end.i + 1))\n",
        "\n",
        "    # Initialize all tokens with 'NIL' labels (no entity)\n",
        "    token_labels = [label_to_index['NIL']] * len(doc)\n",
        "\n",
        "    # Assign correct entity labels to tokens based on provided labels\n",
        "    for (start, end), label in zip(entity_spans, labels):\n",
        "        for token in doc:\n",
        "            if start <= token.idx < end:  # Check if token falls within entity span\n",
        "                token_labels[token.i] = label  # Assign label\n",
        "\n",
        "    # Store results for the current text sample\n",
        "    all_token_labels.append(token_labels)\n",
        "    all_token_spans.append(entity_spans)\n",
        "    all_original_word_spans.append(original_word_spans)\n",
        "    all_length.append(len(doc))\n",
        "\n",
        "    # Tokenize text and move tensors to the device (GPU/CPU)\n",
        "    inputs = ft_tokenizer(text, entity_spans=entity_spans, return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "    # Perform inference with the model (disable gradient calculation for efficiency)\n",
        "    with torch.no_grad():\n",
        "        outputs = ft_model(**inputs)\n",
        "\n",
        "    # Store model logits for later analysis\n",
        "    all_logits.extend(outputs.logits.tolist())"
      ],
      "metadata": {
        "id": "wQWxoww1UjlQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_token_labels), len(all_token_spans), len(all_logits), len(all_original_word_spans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAGs6Ac9Ujg6",
        "outputId": "29e97aeb-04ca-4bd8-ffd8-fda2cd891f14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 20, 20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract ground truth labels from the test dataset\n",
        "final_labels = [label for label in test_examples['labels']]\n",
        "\n",
        "# Initialize a list to store final predictions\n",
        "final_predictions = []\n",
        "\n",
        "# Iterate over each example in the dataset\n",
        "for example_index, example in enumerate(all_original_word_spans):\n",
        "\n",
        "    # Retrieve the model's logits (confidence scores) for the current example\n",
        "    logits = all_logits[example_index]\n",
        "\n",
        "    # Get the maximum logit value and its corresponding index for each span\n",
        "    max_logits = np.max(logits, axis=1)   # Highest confidence score per span\n",
        "    max_indices = np.argmax(logits, axis=1)  # Predicted label index per span\n",
        "\n",
        "    # Retrieve original spans for the current example\n",
        "    original_spans = example\n",
        "    predictions = []\n",
        "\n",
        "    # Process predictions by filtering out \"NIL\" spans\n",
        "    for logit, index, span in zip(max_logits, max_indices, original_spans):\n",
        "        if index != 0:  # The span is not NIL (i.e., it has a valid label)\n",
        "            predictions.append((logit, span, ft_model.config.id2label[index]))  # Store label with its confidence score\n",
        "\n",
        "    # Initialize an IOB2 label sequence with \"O\" (outside entity) for all tokens\n",
        "    predicted_sequence = [\"O\"] * all_length[example_index]\n",
        "\n",
        "    # Sort predictions by confidence (logit score) in descending order\n",
        "    for _, span, label in sorted(predictions, key=lambda o: o[0], reverse=True):\n",
        "\n",
        "        # Ensure no overlapping labels are assigned\n",
        "        if all([o == \"O\" for o in predicted_sequence[span[0] : span[1]]]):\n",
        "            predicted_sequence[span[0]] = \"B-\" + label  # Mark beginning of entity\n",
        "            if span[1] - span[0] > 1:\n",
        "                predicted_sequence[span[0] + 1 : span[1]] = [\"I-\" + label] * (span[1] - span[0] - 1)  # Mark inside tokens\n",
        "\n",
        "    # Store the final predicted label sequence for the example\n",
        "    final_predictions.append(predicted_sequence)"
      ],
      "metadata": {
        "id": "l74-L7IyUjcr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMBje883apjR",
        "outputId": "f1c38124-3bc9-4f49-f175-36f6dd20bcc4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, I am going to convert the true labels (`final_labels`) into the IOB2 format. Currently, it is a list of lists containing label indices instead of the label strings needed for inference.**"
      ],
      "metadata": {
        "id": "i1zl26MZbjYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pId92jIa7Dz",
        "outputId": "ae11187f-9fdc-402b-f6a1-b14bdfd1a5f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 5], [4, 1, 6, 4], [4, 1, 4, 4], [4, 1], [1, 1, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_references_to_iob(labels):\n",
        "    \"\"\"Converts a list of label indices to IOB format, preserving all labels including 'O'.\"\"\"\n",
        "    iob_labels = []\n",
        "\n",
        "    for label_seq in labels:\n",
        "        iob_seq = []\n",
        "        prev_label = None  # Keep track of the previous label\n",
        "\n",
        "        for i, label_index in enumerate(label_seq):\n",
        "            label = index_to_label[label_index]\n",
        "\n",
        "            if label == \"NIL\":\n",
        "                iob_seq.append(\"O\")  # Preserve 'O' labels for non-entity tokens\n",
        "                prev_label = None  # Reset previous label\n",
        "            else:\n",
        "                if prev_label is None or prev_label != label:\n",
        "                    iob_seq.append(\"B-\" + label)  # Start of a new entity\n",
        "                else:\n",
        "                    iob_seq.append(\"I-\" + label)  # Continuation of the same entity\n",
        "                prev_label = label  # Update the previous label\n",
        "\n",
        "        iob_labels.append(iob_seq)  # Append sequence correctly\n",
        "\n",
        "    return iob_labels"
      ],
      "metadata": {
        "id": "E51xgdiCUjYe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_labels_iob = convert_references_to_iob(all_token_labels)"
      ],
      "metadata": {
        "id": "uilfKu5KUjUa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_labels_iob), len(final_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6LA-ZBPUjQK",
        "outputId": "bbd5e485-4e7b-4164-8169-b0a309663efb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(seqeval.metrics.classification_report(final_labels_iob, final_predictions, digits=4))"
      ],
      "metadata": {
        "id": "HfxyDB3hUjL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}